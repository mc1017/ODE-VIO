{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for Visualising Data in KITTI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes for each size and variables:\n",
    "\n",
    "seq_len = 11 (For LSTM)\n",
    "imgs.shape = (16, 11, 3, 256, 512)\n",
    "imus.shape = (16, 101, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import scipy.io as sio\n",
    "import os\n",
    "os.chdir('/home/marco/Documents/NeuralCDE-VIO')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Within function `make_dataset()`, it downloads imus data with shape (observations, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Tue Jun  8 12:49:06 2021', '__version__': '1.0', '__globals__': [], 'imu_data_interp': array([[ 1.50400292e+00,  2.93219112e-01,  9.87464000e+00,\n",
      "        -9.84725158e-04,  2.56165963e-02, -3.63842585e-04],\n",
      "       [ 1.49926763e+00,  2.95990398e-01,  9.87622172e+00,\n",
      "        -9.34152863e-04,  2.54884553e-02, -2.27065589e-04],\n",
      "       [ 1.49453234e+00,  2.98761684e-01,  9.87780345e+00,\n",
      "        -8.83580569e-04,  2.53603142e-02, -9.02885929e-05],\n",
      "       ...,\n",
      "       [-1.98989915e-01,  4.97848027e-01,  1.01454150e+01,\n",
      "         2.52250288e-02, -3.79217315e-02, -6.68370680e-03],\n",
      "       [-1.80242558e-01,  5.51190003e-01,  1.01775700e+01,\n",
      "         2.14899408e-02, -3.92741115e-02, -6.53726925e-03],\n",
      "       [-8.41972307e-02,  5.11396567e-01,  1.02197699e+01,\n",
      "         1.68026044e-02, -4.04377488e-02, -6.10780227e-03]])}\n",
      "(45401, 6)\n"
     ]
    }
   ],
   "source": [
    "root = Path('/mnt/data0/marco/Visual-Selective-VIO/data')\n",
    "imus = sio.loadmat(root/'imus/{}.mat'.format('00'))\n",
    "print(imus)\n",
    "print(imus['imu_data_interp'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Obtaining Pose Data: `make_dataset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/marco/Documents/NeuralCDE-VIO/notebooks/exploratory', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/marco/Documents/NeuralCDE-VIO/venv/lib/python3.10/site-packages']\n",
      "(4541, 4, 4)\n",
      "(4540, 6)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "from src.data.utils import rotationError, read_pose_from_text\n",
    "root = Path('/mnt/data0/marco/Visual-Selective-VIO/data')\n",
    "poses, poses_rel = read_pose_from_text(root/'poses/{}.txt'.format('00'))\n",
    "print(poses.shape)\n",
    "print(poses_rel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digging deeper into `read_pose_from_text()`, we found that the poses information are stored as a NX12 table in poses.txt, where each row represent 1 measurement.\n",
    "\n",
    "We use the following functions in utils to construct 4X4 homogenous matrix for pose representation.\n",
    "In computer vision and robotics, a 4x4 matrix is commonly used to represent a 3D homogeneous transformation. A homogeneous transformation matrix allows us to represent translation, rotation, and scale in a unified way. The 4x4 matrix is convenient for representing 3D transformations because it can handle translations as well as rotations and scaling.\n",
    "\n",
    "The 12 parameters you see in the code (presumably from a line in the KITTI odometry dataset) are used to construct a 3x4 matrix, where the first 3 columns represent the rotation and scaling part, and the last column represents the translation part.\n",
    "\n",
    "For example, the 3x4 matrix might look like this:\n",
    "\n",
    "\\begin{bmatrix} \n",
    "    r_{11} & r_{12} & r_{13} & t_1 \\\\\n",
    "    r_{21} & r_{22} & r_{23} & t_2 \\\\\n",
    "    r_{31} & r_{32} & r_{33} & t_3 \n",
    "\\end{bmatrix} \n",
    "\n",
    "Here:\n",
    "- \\( r_{ij} \\) represents the elements of the rotation and scaling submatrix.\n",
    "- \\( t_1, t_2, t_3 \\) represent the translation vector.\n",
    "\n",
    "To make it a 4x4 homogeneous transformation matrix, an extra row \\([0, 0, 0, 1]\\) is appended at the bottom:\n",
    "\n",
    "\\begin{bmatrix} \n",
    "    r_{11} & r_{12} & r_{13} & t_1 \\\\\n",
    "    r_{21} & r_{22} & r_{23} & t_2 \\\\\n",
    "    r_{31} & r_{32} & r_{33} & t_3 \\\\\n",
    "    0 & 0 & 0 & 1 \n",
    "\\end{bmatrix} \n",
    "\n",
    "This homogeneous transformation matrix can be applied to 3D points using matrix multiplication, allowing for efficient transformations of 3D coordinates between different coordinate frames. It is a standard representation widely used in computer vision and robotics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "_EPS = np.finfo(float).eps * 4.0\n",
    "\n",
    "# With the 3x4 transformation matrix, we add 1 row to the bottom, making it a \n",
    "# 4x4 homogeneous Matrix\n",
    "def read_pose(line):\n",
    "    '''\n",
    "    Reading 4x4 pose matrix from .txt files\n",
    "    input: a line of 12 parameters\n",
    "    output: 4x4 numpy matrix\n",
    "    '''\n",
    "    values= np.reshape(np.array([float(value) for value in line.split(' ')]), (3, 4))\n",
    "    Rt = np.concatenate((values, np.array([[0, 0, 0, 1]])), 0)\n",
    "    return Rt\n",
    "   \n",
    "# Poses information is stored as a N x 12 table, where N is the number of\n",
    "# frames of this sequence. Row i represents the i'th pose of the left camera\n",
    "# coordinate system (i.e., z pointing forwards) via a 3x4 transformation\n",
    "# matrix.\n",
    "\n",
    "def read_pose_from_text(path):\n",
    "    with open(path) as f:\n",
    "        lines = [line.split('\\n')[0] for line in f.readlines()]\n",
    "        poses_rel, poses_abs = [], []\n",
    "        values_p = read_pose(lines[0])\n",
    "        poses_abs.append(values_p)            \n",
    "        for i in range(1):\n",
    "            values = read_pose(lines[i])\n",
    "            poses_rel.append(get_relative_pose_6DoF(values_p, values)) \n",
    "            values_p = values.copy()\n",
    "            poses_abs.append(values) \n",
    "        poses_abs = np.array(poses_abs)\n",
    "        poses_rel = np.array(poses_rel)\n",
    "        \n",
    "    return poses_abs, poses_rel\n",
    "\n",
    "def get_relative_pose(Rt1, Rt2):\n",
    "    '''\n",
    "    Calculate the relative 4x4 pose matrix between two pose matrices\n",
    "    '''\n",
    "    Rt1_inv = np.linalg.inv(Rt1)\n",
    "    Rt_rel = Rt1_inv @ Rt2\n",
    "    return Rt_rel\n",
    "\n",
    "def get_relative_pose_6DoF(Rt1, Rt2):\n",
    "    '''\n",
    "    Calculate the relative rotation and translation from two consecutive pose matrices \n",
    "    '''\n",
    "    \n",
    "    # Calculate the relative transformation Rt_rel\n",
    "    Rt_rel = get_relative_pose(Rt1, Rt2)\n",
    "\n",
    "    R_rel = Rt_rel[:3, :3]\n",
    "    t_rel = Rt_rel[:3, 3]\n",
    "\n",
    "    # Extract the Eular angle from the relative rotation matrix\n",
    "    x, y, z = euler_from_matrix(R_rel)\n",
    "    theta = [x, y, z]\n",
    "\n",
    "    pose_rel = np.concatenate((theta, t_rel))\n",
    "    return pose_rel\n",
    "\n",
    "def euler_from_matrix(matrix):\n",
    "    '''\n",
    "    Extract the eular angle from a rotation matrix\n",
    "    '''\n",
    "    M = np.array(matrix, dtype=np.float64, copy=False)[:3, :3]\n",
    "    cy = math.sqrt(M[0, 0] * M[0, 0] + M[1, 0] * M[1, 0])\n",
    "    ay = math.atan2(-M[2, 0], cy)\n",
    "    if ay < -math.pi / 2 + _EPS and ay > -math.pi / 2 - _EPS:  # pitch = -90 deg\n",
    "        ax = 0\n",
    "        az = math.atan2(-M[1, 2], -M[0, 2])\n",
    "    elif ay < math.pi / 2 + _EPS and ay > math.pi / 2 - _EPS:\n",
    "        ax = 0\n",
    "        az = math.atan2(M[1, 2], M[0, 2])\n",
    "    else:\n",
    "        ax = math.atan2(M[2, 1], M[2, 2])\n",
    "        az = math.atan2(M[1, 0], M[0, 0])\n",
    "    return np.array([ax, ay, az])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.000000e+00  9.043680e-12  2.326809e-11  5.551115e-17]\n",
      "  [ 9.043683e-12  1.000000e+00  2.392370e-10  3.330669e-16]\n",
      "  [ 2.326810e-11  2.392370e-10  9.999999e-01 -4.440892e-16]\n",
      "  [ 0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00]]\n",
      "\n",
      " [[ 1.000000e+00  9.043680e-12  2.326809e-11  5.551115e-17]\n",
      "  [ 9.043683e-12  1.000000e+00  2.392370e-10  3.330669e-16]\n",
      "  [ 2.326810e-11  2.392370e-10  9.999999e-01 -4.440892e-16]\n",
      "  [ 0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00]]]\n",
      "(2, 4, 4)\n",
      "[[-2.06900257e-26 -2.47439078e-28  9.95909557e-29  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "(1, 6)\n"
     ]
    }
   ],
   "source": [
    "poses, poses_rel = read_pose_from_text(root/'poses/{}.txt'.format('00'))\n",
    "print(poses)\n",
    "print(poses.shape)\n",
    "print(poses_rel)\n",
    "print(poses_rel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we see that there are 2 4x4 matrix, and the difference of the two gives the 1x6 vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding IMU Timestamps stored in KITTI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_dir = \"/mnt/data0/marco/Visual-Selective-VIO/data/raw/2011_09_26/2011_09_26_drive_0001_sync/oxts/timestamps.txt\"\n",
    "image_dir = \"/mnt/data0/marco/Visual-Selective-VIO/data/raw/2011_09_26/2011_09_26_drive_0001_sync/image_02/timestamps.txt\"\n",
    "def count_lines_in_file(file_path):\n",
    "    \"\"\"Count the number of lines in a text file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The path to the text file.\n",
    "        \n",
    "    Returns:\n",
    "        int: The number of lines in the file.\n",
    "    \"\"\"\n",
    "    line_count = 0\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line_count += 1\n",
    "    return line_count\n",
    "\n",
    "print(count_lines_in_file(timestamp_dir))\n",
    "print(count_lines_in_file(image_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
