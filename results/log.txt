Starting Point:
1. Train_seq [4], approximate straight line after 40 epoch
2. Train_seq [10], approximate trajectory after 80 epoch
3. Train_seq [4, 10]. Test_seq [4, 10], trash results. Does not generalise well. 
4. Tran_Seq [1, 2, 4, 10], Test_seq [1, 2, 4, 10], increased regressor model capacity, 13 epochs, does not fit well
5. Train_seq [4, 10], Test_seq [4 10], increased regressor model capacity, 100 epochs, final tanh activation layer, intermediate tanh gives nan, changed to softplu. Rubbish training after 40 epochs.
6. train_seq [1], test_seq [1]. same setup. Does not work well
7. train_seq [1], test_seq [1], decrease warmup lr, increase fine tune lr. 

Possible experimentations from here
- GRU, LSTM
- Neural CDE
- Initialise hc + Repeat use of hc after each sequence
- Train on a smaller sequence
- Verify Network Construction by restructuring training script
- Absolute Tolerance (atol),  Relative Tolerance (rtol) 
https://uk.mathworks.com/help/matlab/math/troubleshoot-common-ode-problems.html
- Evaluation time stamps length

8. Repeat use of hc, train_seq [4], val_seq [4], 100 epoch does not give good rotation results
9. Repeat use of hc, 400 epoch, does not seem good. use non-overlapping sequences

* Pose error calculation uses relative pose, however pose regressor regress to absolute pose. Need to feed in the differential?

10. Use hidden states differential with stacked regressor, Revert back to overlapping sequences
11. Use hidden state differential by deducting hidden states, great improvement in training
12. Reduced atol, rtol to 10^-9 and 10^-6
13. Restore stepped lr and ep. Actually produced worse results. Should fine tune lr
14. train_seq [01 02 04], val_seq [01 02 04 10]
15. train_seq [04 10], val_seq [04, 10]. 04 seems not bad, but 10 goes wrong direction. should try to train 10 alone
16. train_seq [10], val_seq [10], does seems to resembles the path, but takes a long time. 

* Multiple Configurations For RNN input
1. output, new_hidden_states = self.rnn(fused_features.squeeze(1), new_hidden_states)
2. regress on output / regress on new_hidden_states/ regress on new_hidden_states + old_hidden_states

17. train_seq [10], val_seq [10], use rnn + stacked hidden states. Slow convergence, curly lines
18. train_seq [10], val_seq [10], use rnn + deducted hidden states. Straight lines like in 11. 
19. train_seq [10], val_seq [10], use gru + deducted hidden states. Converges even slower. Changed back to rnn
20. train_seq [4 10], val_seq [04 10], use rnn, 04 converges but sway, 10 froms a relatively similar shape but does not fit entirely

* Switched to regressing absolute pose from the first frame, then deduct the absolute pose from the previous prediction. 
21. train_seq [04], val_seq [04], use rnn, deduct predicted absoute pose from a frame before. 

* Maybe also test capping explotion or diminishing hidden states?
22. train_seq [10], val_seq [10], tried on path 10
23. train_seq [4, 10], val_seq [04, 10], it trains but not that good.
24. train_seq [4, 10], val_seq [04, 10], tried a few epochs for gru cell instead of rnncell, asbolutely garbage

* Forgot to initialise rnncell and grucell. Try again after ensuring correct initialisation. Can write in report about the different initialisation
* Forgot to add reduction = sum for loss calculation. 
25. train_seq [4, 10], val_seq [04, 10], added initialisation with gru, garbage training
26. train_seq [4, 10], val_seq [04, 10], added initialisation with rnn, normal rnn training
27. train_seq [01 02 04 05 10], val_seq [01 02 04 05 10], tried initialisation with rnn long training

* Revert back to differential with deduction
28. train_seq [01 02 04 05 10], val_seq [01 02 04 05 10], tried initialisation with rnn long training 

* Added data shuffling, Maybe that improves generalisation? 
29. train_seq [04 05 07 10], val_seq [04 05 07 10], data shuffling, tried initialisation with rnn long training SHUFFLING IS THE MAIN ISSUE!!! 

Why shuffling is important?
Prevent Overfitting: Without shuffling, the model might learn the order of the sequences rather than the underlying patterns. If the dataset contains sequences in a specific order (e.g., easy to hard, or by different driving conditions), the model could pick up on this sequence and overfit to that pattern. 
Balance Dataset: If the data is not shuffled, and there are imbalances in the dataset (e.g., certain types of sequences are clustered together), the model might learn to perform well on the overrepresented type at the expense of others. Shuffling helps to ensure that each mini-batch is more representative of the overall distribution of the data.
Stochastic Gradient Descent Efficiency: Models are often trained using stochastic gradient descent (SGD) or its variants. These algorithms assume that each mini-batch is an unbiased estimate of the overall gradient. 

* Now try to regress absolute pose then find the relative difference from last frame.
30. train_seq [04 05 07 10], val_seq [04 05 07 10], does not work well, error does not converge.

31. train_seq [04 05 07 10], val_seq [04 05 07 10], test using gru instead of rnn, gru fail to generalise and performed badly. 

* Introduced Dropout layer and see if it makes training better.
32. train_seq [04 05 07 10], val_seq [04 05 07 10], gru still performs badly
33. train_seq [04 05 07 10], val_seq [04 05 07 10], rnn to see if drop out layer makes it better. Does not make it better. Seems to trains poorly
34. train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10]. Perform actual training.

* Removed Dropout layer. Made it worse. Seems like overfitting did not happen, more like underfitting
36. train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10]. Perform actual training rnn no dropout training well at first, but then suddenly collapsed into circles after 11 epochs. Maybe need to reshuffle data after every single epoch.

* Added reshuffling at the start of each epoch
37. train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10]. Converges to circle at epoch 11, then loss comes back down and converge nicely. Best translation loss ~t_rel: 21.0623, r_rel: 4.2701
38. tested loading saved model. It works.

* Debugging Image Loading and Data sources
39. 

40. train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10]. Implemented Gradient Clipping at value 5. Seems like gradient clipping is effective at lowering the loss spike, but spike still occurs.

41. train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10], gradient clip=1

42. train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10], changed learning rate from 5e-4, 1e-4, 5e-5 to 5e-4, 5e-5, 1e-6

43. Tested run and continue experiments logging. Also run from epoch 6. every single time epoch 7 explodes. 
44. train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10], changed lr [5e-4, 5e-5, 1e-6] to lr [1e-4, 1e-5, 1e-6] performed worse with lower training rate. Try higher
45. train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10] new lr [1e-3, 1e-4, 1e-5] 


Things to test from here: 
1. Neural CDE
2. LTC Networks
3. Implement Dropout mechanism
4. Gradient Accumulation
5. Learning Rate decay/ lower learning rate
6. Linear Probing

46. train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10] restore restore lr [1e-4, 1e-5, 1e-6] Froze Encoder train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10] restore restore lr [1e-4, 1e-5, 1e-6] Unfroze Encoder at 50 epochs. Seems like the finetuning of encoder is not the bottleneck. 

Suspecting bottleneck might be in the NeuralODE network. Try increase the number of layers and keep frozen encoder

Also changed loggin formats
47. train_seq [00 02 08 09], val_seq [01 04 05 06 07 10] increase ode_layers to 5. non frozen encoder. Does not outperform 3 layers.

Added data dropout functionality
48. train_seq [00 02 08 09], val_seq [01 04 05 06 07 10] increase ode_layers to 5. non frozen encoder same config but data_dropout 0.1, eval_data_dropout 0.1. Dropout does affect training. Ode_layers does not help a lot. 

Maybe try using soft/hard fusion would work better. 
49. train_seq [00 02 08 09], val_seq [01 04 05 06 07 10] ode_layers 5. frozen encoder for space, soft cat. 
50. train_seq [00 02 08 09], val_seq [01 04 05 06 07 10] ode_layers 5. frozen encoder for space, hard cat.

soft/hard cat are better than cat, but soft> hard

50. train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10], run with gru to see if its better. 
51. train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10], run with SGD optimiser with GRU
GRU still rubbish 

52. train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10], run with SGD optimiser with rnn. SGD is rubbish
53. train_seq [00 02 08 09], val_seq [00 01 02 04 05 06 07 08 09 10], run with SGD optimiser with rnn, old lr [5e-4, 5e-5 1e-6] new lr [1e-4, 1e-5, 1e-6]
Both does not work well. SGD Optimiser is not as good as Adam. Revert back to Adam

Try new architecture levels. Maybe increase ODE Hidden?
54. Increased ode_hidden to 1024, lr [1e-3, 1e-4, 1e-5]
55. same config as above, ode_hidden=1024 batch_size=26
57.  lower ode_hidden_layers to 2, ode_hidden = 512 batch_size=12

Between 55 and 57, 57 does not converge but 55 performs well. Could be due to the batch size difference/ ODE layer is the bottleneck.
Can try: 1. 4 ode layers vs 2 ode layers + Gradient Accumulation. 

58. train_seq [00 02 08 09], val_seq [01 04 05 06 07 10] batch size 12 4 ode layers. If it performs better then 57 then it is ode that's the bottleneck runs better but not great
59. train_seq [00 02 08 09], val_seq [01 04 05 06 07 10] batch size 26 2 ode layers.  runs ok but not great

Test using multiple RNN layers. Maybe it is the bottleneck. Try it with regressing output like in Visual Selective VIO.  
61. train_seq [00 02 08 09], val_seq [01 04 05 06 07 10] 2 layers of rnn. regress directly on output. 
62. train_seq [00 02 08 09], val_seq [01 04 05 06 07 10] 2 layers of rnn. regress on difference of initial and new states
63. train_seq [00 02 08 09], val_seq [01 04 05 06 07 10] 3 layers of rnn. regress on output directly. 




100. train_seq [00 02 08 09], val_seq [01 04 05 06 07 10] first try Neural CDE. Using Adjoint, memory takes 10GB with 2cde layers, 256 cde hidden
Weird that adjoint method does not improve memory usage. It does takes much longer time. 